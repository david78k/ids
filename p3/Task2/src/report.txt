Questions


Todo list


How to compile and run
- mpicc -foepnmp -std=c99 -o out file
- mpirun [--nolocal] [-np 4] [-machinefile machinefile] out
	where -np is the number of processors

implementation methods, experimental settings, outputs and corresponding
conclusions

implementation methods
- c++ standard library (stl) is used.
- At first, unordered_map is used for hash tables. Later, I realized that the
  order of the output is wrong. So, I used map under stl.
- too hard to send vector type: when sending key-value pair list to each processor, I had to convert
  the vector of key-value pairs to 2-dimensional int array.
- maximum number of message (int array): 16375*2 = 32760 (integers)

experimental settings
- output order messy without synchronization: needed barrier
- compare single processor and multiprocessors

outputs and corresponding conclusions
- output format: key and sum of values are separated by a tab
- single processor is faster than multiprocessors. this is because the dataset
  size is too small to take advantage of parallel processing. Rather,
communicaion overhead would've dominate the running time.

- What are you looking for regarding performance results in the project
  report?
Mainly refer to the output results, and based on this you need to give some
analysis of advantages using corresponding parallel computing method (not need
too much). Additionally for the implementation, you need to give more details.
