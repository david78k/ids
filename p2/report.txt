1. What is your data processing pipeline? (Graphs and words description)
- pipelining tables (dependencies): enron => enron_most_sent/enron_most_received => enron_most_emails/enron_outside_sent/enron_outside_received => enron_outside
  enron => enron_most_corresp => enron_corresp_pair
  enron_most_sent/enron_most_received => enron_outside_sent/enron_outside_received => enron_outside

2. What kind of analytics do you apply on the dataset? What are the Hive queries?
- For Hive queries, refer to the attachments.

- Enron dateset: After the recipient list in 'cc' column is included, the rank has changed when comparing to the list without cc.
  e.g., steven.kean@enron.com takes the 3rd from 4th
  This may indicate the importance of the person.

3. Which visualization do you use on the dataset using Tableau?


4. What are the programming lessons? And what are the good resources you found?
- whenever we found a bug, we needed to rerun the relevant queries.

- collect_set 

- good resource for data manipulation when dealing with rows and columns
https://cwiki.apache.org/confluence/display/Hive/LanguageManual+UDF
- Lateral view:
  https://cwiki.apache.org/confluence/display/Hive/LanguageManual+LateralView

- In the first place, it was too difficult to split a string into multiple
  rows with Hive. Ever since we realized that Hive provides a numberous
functions for manipulation of data (e.g., split, explode, trim) everything went well suddenly.

- It was so embarrassing that multiline comments /*..*/ are not supported in Hive scripts. Before I knew this, I kept getting an error message.
NoViableAltException(15@[])
        at
org.apache.hadoop.hive.ql.parse.HiveParser.statement(HiveParser.java:892)
        at
org.apache.hadoop.hive.ql.parse.ParseDriver.parse(ParseDriver.java:190)
        at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:418)
        at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:337)
        at org.apache.hadoop.hive.ql.Driver.run(Driver.java:902)
        at
org.apache.hadoop.hive.cli.CliDriver.processLocalCmd(CliDriver.java:259)
        at org.apache.hadoop.hive.cli.CliDriver.processCmd(CliDriver.java:216)
        at
org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:413)
        at
org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:348)
        at
org.apache.hadoop.hive.cli.CliDriver.processReader(CliDriver.java:446)
        at
org.apache.hadoop.hive.cli.CliDriver.processFile(CliDriver.java:456)
        at org.apache.hadoop.hive.cli.CliDriver.run(CliDriver.java:712)
        at org.apache.hadoop.hive.cli.CliDriver.main(CliDriver.java:614)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at
sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
        at
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:606)
        at org.apache.hadoop.util.RunJar.main(RunJar.java:156)
FAILED: ParseException line 3:0 cannot recognize input near '/' '*' 'drop'


5. What is the runtime experience for queries and visualizations?
- it was surprising that inserting the enron dataset which is almost 1GB took only a few minutes.

- runtime for the enron dataset is short. It usually takes 1-2 minutes for a
  single query.

6. What difficulties you faced and what you learned from this project?
- The data given to us didn't fit into Hive format as the enron data file
  contains ^M character which is considered as tab. Hence, we had to remove
the character before loading to Hive table.

- parsing is the most difficult part.
