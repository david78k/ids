workload division
- Yifei Sun: visualization of result data using Tableau
- Tae Seung Kang: SQL queries, data processing using Hive, report, presentation ppt files

1. What is your data processing pipeline? (Graphs and words description)
- pipelining tables (dependencies): enron => enron_most_sent/enron_most_received => enron_most_emails/enron_outside_sent/enron_outside_received => enron_outside
  enron => enron_most_corresp => enron_corresp_pair
  enron_most_sent/enron_most_received => enron_outside_sent/enron_outside_received => enron_outside
  enron_ken_subjects
  enron_lay_subjects

- netflix_titles/netflix_ratings => netflix_most_watched =>
  netflix_most_watched_periods
  netflix_most_popular_periods
  
  netflix_titles/netflix_ratings => netflix_most_popular_periods
  netflix_titles/netflix_ratings => netflix_similar_pairs

2. What kind of analytics do you apply on the dataset? What are the Hive queries?
- For Hive queries, refer to the attachments.

- Enron dateset: After the recipient list in 'cc' column is included, the rank has changed when comparing to the list without cc.
  e.g., steven.kean@enron.com takes the 3rd from 4th in
enron_most_received.txt
  This may indicate the importance of the person.

3. Which visualization do you use on the dataset using Tableau?


4. What are the programming lessons? And what are the good resources you found?
- whenever we found a bug, we needed to rerun the relevant queries.

- collect_set 

- good resource for data manipulation when dealing with rows and columns
https://cwiki.apache.org/confluence/display/Hive/LanguageManual+UDF
- Lateral view:
  https://cwiki.apache.org/confluence/display/Hive/LanguageManual+LateralView

- In the first place, it was too difficult to split a string into multiple
  rows with Hive. Ever since we realized that Hive provides a numberous
functions for manipulation of data (e.g., split, explode, trim) everything went well suddenly.

- It was so embarrassing that multiline comments /*..*/ are not supported in Hive scripts. Before I knew this, I kept getting an error message.
NoViableAltException(15@[])
        at
org.apache.hadoop.hive.ql.parse.HiveParser.statement(HiveParser.java:892)
        at
org.apache.hadoop.hive.ql.parse.ParseDriver.parse(ParseDriver.java:190)
        at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:418)
        at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:337)
        at org.apache.hadoop.hive.ql.Driver.run(Driver.java:902)
        at
org.apache.hadoop.hive.cli.CliDriver.processLocalCmd(CliDriver.java:259)
        at org.apache.hadoop.hive.cli.CliDriver.processCmd(CliDriver.java:216)
        at
org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:413)
        at
org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:348)
        at
org.apache.hadoop.hive.cli.CliDriver.processReader(CliDriver.java:446)
        at
org.apache.hadoop.hive.cli.CliDriver.processFile(CliDriver.java:456)
        at org.apache.hadoop.hive.cli.CliDriver.run(CliDriver.java:712)
        at org.apache.hadoop.hive.cli.CliDriver.main(CliDriver.java:614)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at
sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
        at
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:606)
        at org.apache.hadoop.util.RunJar.main(RunJar.java:156)
FAILED: ParseException line 3:0 cannot recognize input near '/' '*' 'drop'


- remove duplicates of pair such (a, b) and (b, a): set the order rule a < b

5. What is the runtime experience for queries and visualizations?
- it was surprising that inserting the enron dataset which is almost 1GB took only a few minutes.

- runtime for the enron dataset is short. It usually takes 1-2 minutes for a
  single query.

- inserting the netflix movie titles data took 0.418 seconds.
  inserting the netflix movie ratings data took 25.485 seconds.
  select count(*) from ratings took 45.799 seconds.
  select count(distinct cid) from netflix_ratings: 170.97 seconds
  
  most watched movies: 138.683 seconds
  nested query took 3min longer than non-nested query.
  triple join query to get the list of similar movie pairs took the longest time.

- netflix similar pairs from 1000 ratings: 670.259 seconds
  estimated time for all ratings: 670*0.1M seconds = 67M seconds = (1m 7s) * 1M
  netflix similar pairs from 10000 ratings: 679.054 seconds
  estimated time for all ratings: 679*0.01M seconds = 11m 19s * 10000 
  netflix similar pairs from 100000 ratings: 618.11 seconds
  estimated time for all ratings: 618*0.001M = 10m 18s * 1000 = 10000m + 5h =
166h 40m + 5h = 171h 40m = 7days 3h 40m
  netflix similar pairs from 200000 ratings: 727.625 seconds
  estimated time for all ratings: 728*0.0005M = 12m 8s * 500 = 6000m = 1440m *
4 = 4 days
  netflix similar pairs from 300000 ratings: 731.125 seconds
  estimated time for all ratings: 731*0.0003M = 12m * 300 = 4000m = 1440m * 3
= 3 days
  netflix similar pairs from 400000 ratings: 734.332 seconds
  estimated time for all ratings: 734*0.0002M = 12m * 200 = 2400m = 1440m * 2
= 2 days
  netflix similar pairs with greater than 100 votes from 500000 ratings: 1507.353 seconds
  estimated time for all ratings: 1507*0.0002M = 25m * 200 = 5000m = 1440m * 3
= 3 days
  netflix similar pairs with greater than 50 votes from 500000 ratings: 1507.743 seconds
  estimated time for all ratings: 1508*0.0002M = 25m * 200 = 5000m = 1440m * 3
= 3 days
  netflix similar pairs with greater than 4 votes from 500000 ratings: 1273.538 seconds
  estimated time for all ratings: 1274*0.0002M = 21m * 200 = 4800m = 1440m * 3
= 3 days
  netflix similar pairs with greater than 100 votes from 500000 ratings: 372.243 seconds
  estimated time for all ratings: 372*0.0002M = 7m * 200 = 1400m = 1440m * 1 = 1 day

  netflix similar pairs with greater than 100 votes and rating > 3 from 1M ratings: 918.207 seconds
  estimated time for all ratings: 734*0.0002M = 12m * 200 = 2400m = 1440m * 2
  netflix similar pairs with greater than 100 votes from 1M ratings: 1273.538 seconds
  estimated time for all ratings: 734*0.0002M = 12m * 200 = 2400m = 1440m * 2

  netflix like X pairs with greater than or equal to 100 votes and rating > 3 from 1M ratings: 12m29.844s
  estimated time for all ratings: 13m * 100 = 13m * 100 = 1300m = 1440m * 1 =
1 day
  netflix like X pairs with greater than or equal to 100 votes and rating > 3 from 1M ratings: 34m3.077s
  estimated time for all ratings: 13m * 100 = 13m * 100 = 1300m = 1440m * 1 =
1 day

  netflix like X pairs with greater than or equal to 100 votes and rating > 3 from entire ratings: 346m12.899s (13799.264 seconds + 432.975 seconds + 6533.251 seconds) = 5h 46m (total of 16708729395 (16.7 billion) records)

  netflix similar pairs with greater than or equal to 100 votes from 1M*100M ratings: 118m36.615s (2h)
  estimated time for all ratings: 2h*100 = 600h = 25days

6. What difficulties you faced and what you learned from this project?
- The data given to us didn't fit into Hive format as the enron data file
  contains ^M character which is considered as tab. Hence, we had to remove
the character before loading to Hive table.

- parsing is the most difficult part.

- desiging SQL queries is the challenging part.

- join on large dataset like movies ratings is challenging with respect to
  runtime. needed to come up with a smart way to deal with the issue. 100M x
100M 

- when I drop a table, it doesn't show up in the table list, but the data file
  still exists in /user/data/warehouse directory. It takes up disk space.
